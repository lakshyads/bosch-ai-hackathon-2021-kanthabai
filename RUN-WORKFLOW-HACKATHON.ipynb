{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "colab": {
      "name": "RUN-WORKFLOW-HACKATHON.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plak66LA-Vns"
      },
      "source": [
        "---\n",
        "---\n",
        "# BOSCH AI HACKATHON 2021\n",
        "---\n",
        "## Team - KanthabAI\n",
        "\n",
        "Members:\n",
        "  - Sanjana  \n",
        "  - Lakshya  \n",
        "  - Abeesh  \n",
        "  - Sachin  \n",
        "  - Shubham\n",
        "  \n",
        "~ Code, data and scripts maintained by Lakshya Dev at https://github.com/lakshyads/bosch-ai-hackathon-2021-kanthabai\n",
        "\n",
        "  \n",
        "---\n",
        "**Content:**  \n",
        "\n",
        "1. Initial Config   \n",
        "2. Prep the environment and data   \n",
        "3. ***Detecting new Images***   \n",
        "4. Training the Yolov5 model   \n",
        "5. Running inferences on training data   \n",
        "6. Test with test data   \n",
        "7. Retraining from last checkpoint   \n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyMiSPak-Vnw"
      },
      "source": [
        "## Initial Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwRawrq--Vnw"
      },
      "source": [
        "available_models = {\n",
        "    1: \"yolov5s.yaml\",\n",
        "    2: \"yolov5m.yaml\",\n",
        "    3: \"yolov5l.yaml\",\n",
        "    4: \"yolov5x.yaml\",\n",
        "    5: \"yolov5s6.yaml\",\n",
        "    6: \"yolov5m6.yaml\",\n",
        "    7: \"yolov5l6.yaml\",\n",
        "    8: \"yolov5x6.yaml\"\n",
        "}\n",
        "\n",
        "selected_model = available_models[7] # Edit this to change the selected model variant of Yolov5\n",
        "weights_path = 'yolov5l6.pt'\n",
        "epochs = 350\n",
        "batch_size = 64\n",
        "image_size = 640\n",
        "# Github pull repo and branch\n",
        "git_branch = 'yolo-l6'\n",
        "git_token = input('Enter github access token to commit/push your training/test/validation runs back to the selected branch. Leave blank to omit : ')\n",
        "\n",
        "# Detecting on new images (set archive path if archived folder else set images path)\n",
        "detect_images_archive_path = ''\n",
        "detect_images_path = ''\n",
        "\n",
        "# Testing Or Detecting on images - set to 'latest' to use last trained weights or set custom path\n",
        "weights_path_for_testing_or_detecting = 'latest'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrtiOyjz-Vny"
      },
      "source": [
        "---\n",
        "# 1. PREP THE ENVIRONMENT AND DATA\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE5TR1O7-Vny"
      },
      "source": [
        "### Setup Git & LFS for downloading repo & dataset & ready the model/env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90yr58Qj-Vnz"
      },
      "source": [
        "# Setup\n",
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git config --global user.email \"lakshyadev@live.com\"\n",
        "!git config --global user.name \"Lakshya from google colab\"\n",
        "\n",
        "# Clone repo\n",
        "!git clone https://github.com/lakshyads/bosch-ai-hackathon-2021-kanthabai.git yolov5\n",
        "%cd /content/yolov5/\n",
        "!git pull\n",
        "!git checkout $git_branch\n",
        "\n",
        "# Install dependencies and give max permissions\n",
        "!pip install -r requirements.txt\n",
        "%cd /content/yolov5/\n",
        "!chmod -R 755 /content/yolov5\n",
        "# Download pretrained weights\n",
        "!/content/yolov5/weights/download_weights.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJV8ZVDc-Vnz"
      },
      "source": [
        "---\n",
        "# 2. DETECTING ON NEW IMAGES\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8W_eBq1-Vn0"
      },
      "source": [
        "### Extract new images from zipped upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnev3Kvg-Vn1"
      },
      "source": [
        "%cd ..\n",
        "!unzip -q $detect_images_archive_path ./detection_images\n",
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6I5_cKk-Vn2"
      },
      "source": [
        "### Runs the detect script.\n",
        "### Update --weights with required weights path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrQ091Zy-Vn3"
      },
      "source": [
        "use_weights = ''\n",
        "if (weights_for_testing_path == 'latest'):\n",
        "  from utils.plots import plot_results\n",
        "  import os\n",
        "  # find the latest run\n",
        "  _, dir_names, _ = next(os.walk('runs/train'))\n",
        "  dir_names.sort()\n",
        "  latest = os.path.join(dirPath, dir_names[-1]) # eg: 'runs/train/exp3'\n",
        "  _, _, latest_run_weights = next(os.walk('latest/weights'))\n",
        "  if ('best.pt' not in set(latest_run_weights)):\n",
        "      use_weights = f'{latest}/weights/last.pt'\n",
        "  else:\n",
        "        use_weights = f'{latest}/weights/best.pt'\n",
        "else:\n",
        "  use_weights = weights_path_for_testing_or_detecting\n",
        "\n",
        "##########################################################\n",
        "!python detect.py --source $detect_images_path --weights $use_weights --img $image_size --save-txt --save-conf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FomLeqS0-Vn4"
      },
      "source": [
        "---\n",
        "# 3. TRAINING THE YOLO-V5 MODEL\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVlXHjVq-Vn4"
      },
      "source": [
        "### Ready the data set included in the above repo \n",
        "#### (Extract and create train & val sets. Set 'make_test_set' to True below to create test set also.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1tHbD--Vn4"
      },
      "source": [
        "\n",
        "# Set to True to create test set\n",
        "make_test_set = False\n",
        "\n",
        "# =================================================\n",
        "%cd /content/yolov5/\n",
        "# Unzip dataset\n",
        "!unzip -q ./data/final-data-full.zip -d /content/yolov5/data/dataset/\n",
        "# =================================================\n",
        "\n",
        "if(make_test_set is False):\n",
        "  #split dataset without test set\n",
        "  !python /content/yolov5/data-utils/split_train_val_test.py --images /content/yolov5/data/dataset --labels /content/yolov5/data/dataset --out /content/yolov5/data/dataset --move y --test n\n",
        "else:\n",
        "  #split dataset with test set\n",
        "  !python /content/yolov5/data-utils/split_train_val_test.py --images /content/yolov5/data/dataset --labels /content/yolov5/data/dataset --out /content/yolov5/data/dataset --move y --test y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ0vOpAu-Vn5"
      },
      "source": [
        "### Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSKr-QC0-Vn5"
      },
      "source": [
        "if (weights_path is not None and len(weights_path) > 0):\n",
        "    !python train.py --img $image_size --batch $batch_size --epochs $epochs --data final-data.yaml --cfg $selected_model --weights $weights_path --nosave --cache \n",
        "else:\n",
        "    !python train.py --img $image_size --batch $batch_size --epochs $epochs --data final-data.yaml --cfg $selected_model --weights '' --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RAQE6Lu-Vn6"
      },
      "source": [
        "### Commit runs/train folder updates to git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOo7Ue-R-Vn6"
      },
      "source": [
        "\n",
        "if (git_token is not None and len(git_token) > 0):\n",
        "    import os\n",
        "\n",
        "    # find the latest run\n",
        "    dirPath, dir_names, _ = next(os.walk('runs/train'))\n",
        "    dir_names.sort()\n",
        "    latest = os.path.join(dirPath, dir_names[-1]) # eg: 'runs/train/exp3'\n",
        "\n",
        "    !git lfs track runs/\n",
        "    !git add runs/train\n",
        "    !git commit -m \"Updated $latest data after a new training execution\"\n",
        "    !git push https://$git_token@github.com/lakshyads/bosch-ai-hackathon-2021-kanthabai.git\n",
        "else:\n",
        "    print(\"No valid Github access token found to commit or push changes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywRdISdt-Vn7"
      },
      "source": [
        "---\n",
        "# 4. RUNNING INFERENCES ON TRAINING DATA\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ere-M4l-Vn7"
      },
      "source": [
        "### Initialize Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS3NdkQy-Vn7"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SV1TGQo-Vn8"
      },
      "source": [
        "### Plotting the training results from latest run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFQEuqSX-Vn8"
      },
      "source": [
        "from utils.plots import plot_results\n",
        "import os\n",
        "\n",
        "# find the latest run\n",
        "_, dir_names, _ = next(os.walk('runs/train'))\n",
        "dir_names.sort()\n",
        "\n",
        "latest = os.path.join(dirPath, dir_names[-1]) # eg: 'runs/train/exp3'\n",
        "\n",
        "plot_results(save_dir=f'{latest}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGNK6yVe-Vn8"
      },
      "source": [
        "---\n",
        "# 5. TESTING\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuZUhshq-Vn9"
      },
      "source": [
        "### Update --weights with required weights path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLFaHU1m-Vn9"
      },
      "source": [
        "use_weights = ''\n",
        "if (weights_for_testing_path == 'latest'):\n",
        "  from utils.plots import plot_results\n",
        "  import os\n",
        "  # find the latest run\n",
        "  _, dir_names, _ = next(os.walk('runs/train'))\n",
        "  dir_names.sort()\n",
        "  latest = os.path.join(dirPath, dir_names[-1]) # eg: 'runs/train/exp3'\n",
        "  _, _, latest_run_weights = next(os.walk('latest/weights'))\n",
        "  if ('best.pt' not in set(latest_run_weights)):\n",
        "      use_weights = f'{latest}/weights/last.pt'\n",
        "  else:\n",
        "        use_weights = f'{latest}/weights/best.pt'\n",
        "else:\n",
        "  use_weights = weights_path_for_testing_or_detecting\n",
        "\n",
        "###############################################################33\n",
        "!python test.py --weights $use_weights --data final-data.yaml --img $image_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lYTmo_B-Vn9"
      },
      "source": [
        "### Commit runs/test folder updates to git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPKfTi5M-Vn9"
      },
      "source": [
        "if (git_token is not None and len(git_token) > 0):\n",
        "    import os\n",
        "\n",
        "    # find the latest run\n",
        "    dirPath, dir_names, _ = next(os.walk('runs/train'))\n",
        "    dir_names.sort()\n",
        "    latest = os.path.join(dirPath, dir_names[-1]) # eg: 'runs/test/exp3'\n",
        "\n",
        "    !git lfs track runs/\n",
        "    !git add runs/train\n",
        "    !git commit -m \"Updated $latest data after a new testing execution\"\n",
        "    !git push https://$git_token@github.com/lakshyads/bosch-ai-hackathon-2021-kanthabai.git\n",
        "else:\n",
        "    print(\"No valid Github access token found to commit or push changes\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}