{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRAIN_YOLO_V5_FOR_BOSCH_HACKATHON.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "beH-eBRLUKYG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a73a45ba-4404-4461-a2cb-f17d1d3563cc"
      },
      "source": [
        "import torch \n",
        "torch.cuda.get_device_name(device=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DBmYXVfJrxp"
      },
      "source": [
        "---\n",
        "---\n",
        "# BOSCH AI HACKATHON 2021\n",
        "## Team - KanthabAI\n",
        "\n",
        "Members:\n",
        "  - Sanjana\n",
        "  - Lakshya\n",
        "  - Abeesh\n",
        "  - Sachin\n",
        "  - Shubham\n",
        "  \n",
        "~ Code, data and scripts maintained by Lakshya Dev at https://github.com/lakshyads/bosch-ai-hackathon-2021-kanthabai\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVZUl7GmuXP9"
      },
      "source": [
        "## 1. PREP THE ENVIRONMENT AND DATA\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj0Liegc7T4z"
      },
      "source": [
        "### Setup git LFS for downloading dataset with repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wGrTCqm5O56"
      },
      "source": [
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVO58hItFsT4"
      },
      "source": [
        "### Cloning the model and script files from Github repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBAJ4od4UEL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "057ddd4d-aa35-45f8-e46e-d8c890569495"
      },
      "source": [
        "!git clone https://github.com/lakshyads/bosch-ai-hackathon-2021-kanthabai.git yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl6BjdGkF2BK"
      },
      "source": [
        "### Ready the dataset included with above repo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu5UjPJTW9GW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676707a2-c176-4d9c-c6ec-8b2931b44509"
      },
      "source": [
        "%cd /content/yolov5/\n",
        "!unzip -q ./data/final-data-full.zip -d /content/yolov5/data/dataset/\n",
        "\n",
        "from data-utils.split_train_val_test import split_data\n",
        "\n",
        "# Specify these paths\n",
        "images_dir_path = r\"\"\n",
        "labels_dir_path = r\"\"\n",
        "output_dir_path = r\"\"\n",
        "\n",
        "split_data(images_dir_path=images_dir_path, labels_dir_path=labels_dir_path, output_dir_path=output_dir_path, should_create_test_Set=True, should_move_files=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge9PgTIeF6rI"
      },
      "source": [
        "### Installing the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gypm2_zVcm-m"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO0hmGzsJJtr",
        "outputId": "bd092185-5018-485c-8fa3-e189c8e4a7a5"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhl6GuxJFml5"
      },
      "source": [
        "### Option to connect and use Google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQjhWx2bIz7R"
      },
      "source": [
        "useGDrive = False\n",
        "\n",
        "if (useGDrive == True):\n",
        "  %cd ..\n",
        "  !pip install PyDrive\n",
        "\n",
        "  import os\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "\n",
        "  # Connect GDrive\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  # Download zipped data to Colab from Google Drive\n",
        "  download = drive.CreateFile({'id': '1S23A8_uuiE2zp50qJDSp_xcC294kaFW7'})\n",
        "  download.GetContentFile('train-validate-test-split-data.zip')\n",
        "\n",
        "  %cd /content/yolov5\n",
        "else:\n",
        "  print(\"Google Drive will not be used. set useGDrive = True to use G Drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVwCa5WNRWBz"
      },
      "source": [
        "### Give full permissions to everthing inside /content/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhasEsGmWc15"
      },
      "source": [
        "!chmod -R 755 /content/yolov5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QflTgxaqGAkh"
      },
      "source": [
        "### Download all versions of YOLO-V5 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNXcfvaiQ1NV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabccd3a-93f4-4396-b60f-6754b4bbdff4"
      },
      "source": [
        "!/content/yolov5/weights/download_weights.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUi4h9WKGN_q"
      },
      "source": [
        "# STEPS BEFORE TRAINING CUSTOM DATASET:\n",
        "1. Go to yolov5/data/\n",
        "2. Open coco128.yaml\n",
        "3. Edit the following inside it:\n",
        "    \n",
        "\n",
        "      1.   Training and Test file path\n",
        "      2.   Number of classes and Class names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eonZvqVWHEea"
      },
      "source": [
        "# TRAINING THE YOLO-V5 MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBz4MO3NXVPW"
      },
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 150 --data my_data.yaml --weights yolov5s6.pt --nosave --cache "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r45cXEEV4_Ms"
      },
      "source": [
        "## Upload Best weights to GDrive after training \n",
        "### Also Zip and upload complete runs folder to GDrive as precaution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F3tZZh55GXe"
      },
      "source": [
        "from datetime import datetime\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%d%m%Y-T-%H%M%S\")\n",
        "model_name = 'yolov5s6'\n",
        "epocs = '150'\n",
        "batch_size = '16'\n",
        "initial_weights = 'pre_Init_Weights'\n",
        "# initial_weights = 'custom_Init_Weights'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y0ft0DZ9WZy",
        "outputId": "10f5fae5-de26-4150-b44c-fd0b103e82d2"
      },
      "source": [
        "uploadFileName = f'weights-{model_name}-{initial_weights}-epocs_{epocs}-batch_{batch_size}-{dt_string}.txt'\n",
        "try:\n",
        "  print('\\n Trying to upload best weights to gdrive ...')\n",
        "  upload = drive.CreateFile({'title': uploadFileName, 'parents': [{'id': '1Fo9h4-e-AvGSeYX0Q_086MnP7uquJMyN'}]})\n",
        "  upload.SetContentFile('/content/yolov5/runs/train/exp/weights/last.pt')\n",
        "  upload.Upload()\n",
        "  print(f'\\n Best weights uploaded to google drive. Uploaded file name = {uploadFileName}')\n",
        "except Exception as e:\n",
        "  print(f'\\n Failed to upload best weight file: {uploadFileName} to Google Drive. \\nException details: {e}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC_-Mrh59SU-",
        "outputId": "13563685-87b4-4f0d-b07c-f488acc4f09e"
      },
      "source": [
        "bak_archive_name = f'run-{model_name}-{initial_weights}-epocs_{epocs}-batch_{batch_size}-{dt_string}'\n",
        "bak_archive_path = r'/content/yolov5/backups-for-gdrive/'\n",
        "bak_archive = os.path.join(bak_archive_path, bak_archive_name)\n",
        "dir_to_archive = '/content/yolov5/runs'\n",
        "try:\n",
        "  print('\\n Trying to upload run folder to gdrive ...')\n",
        "  if not os.path.exists(bak_archive_path):\n",
        "    os.makedirs(bak_archive_path)\n",
        "\n",
        "  shutil.make_archive(base_name=bak_archive, root_dir=dir_to_archive, format= 'zip', base_dir=dir_to_archive)\n",
        "\n",
        "  file = drive.CreateFile({'title': f'{bak_archive_name}.zip', 'parents': [{'id': '1Fo9h4-e-AvGSeYX0Q_086MnP7uquJMyN'}]})\n",
        "  file.SetContentFile(f'{bak_archive}.zip')\n",
        "  file.Upload()  \n",
        "  print(f'\\n Run data uploaded to google drive. Uploaded file name = {bak_archive}')\n",
        "except Exception as e:\n",
        "  print(f'\\n Failed to upload Run data to GDrive: {bak_archive} to Google Drive. \\nException details: {e}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJM0X-gQHLig"
      },
      "source": [
        "# VISUALIZING THE TRAINING METRICS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1_iKB2AWonF"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCVi44UrwtKx"
      },
      "source": [
        "## PLOTTING TRAINING RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyc7jqvsw1u3"
      },
      "source": [
        "from utils.plots import plot_results\n",
        "\n",
        "plot_results(save_dir='runs/train/exp3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5STJ2WzXHVPx"
      },
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkcJGHFmcPf3"
      },
      "source": [
        "!python test.py --weights /content/yolov5/runs/train/exp3/weights/best.pt --data my_data.yaml --img 640"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4DIYurLi6w"
      },
      "source": [
        "## Extract new images from zipped upload\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGBpkN0GLnVX",
        "outputId": "c0f8c481-0a12-45df-8327-ffcd17f338d9"
      },
      "source": [
        "%cd ..\n",
        "!unzip -q /content/extracted_images.zip \n",
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9AV1cUQHSLg"
      },
      "source": [
        "# DETECTING ON NEW IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R3aBtYFr_5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35baa2a4-7519-4e1a-c818-6ed1752a0a1e"
      },
      "source": [
        "!python detect.py --source /content/extracted_images --weights /content/last.pt --img 640 --save-txt --save-conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yh2zd2AHkUg"
      },
      "source": [
        "#RETRAINING FROM THE LAST CHECKPOINT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r732j58annF4"
      },
      "source": [
        "!python train.py --weights /content/yolov5/runs/train/exp2/weights/last.pt --epochs 100 --img 416"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1KbWCaf8EVu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSdRPRle8Efp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb72R3868El1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPr3TAxw8Epu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH8SYHXj8Eso"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPXuGBA1IaRa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajBxXQdm8EwW"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc6GDXJ2WRqD"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8kjYG6-taNg"
      },
      "source": [
        "import re\n",
        "path='/content/yolov5/runs/detect/exp3/labels/11_image.txt'\n",
        "myfile=open(path,'r')\n",
        "lines=myfile.readlines()\n",
        "pattern= \"class_name\"\n",
        "\n",
        "cordinate = []\n",
        "for line in lines:\n",
        "  for x in line.splitlines():\n",
        "    cordinate.append([x[1:]])\n",
        "#   if re.search(pattern,line):\n",
        "#     Cord_Raw=line\n",
        "# Cord=Cord_Raw.split(\"(\")[1].split(\")\")[0].split(\"  \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7XYQbIKyyW8"
      },
      "source": [
        "cordinate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbKXsc5O19ol"
      },
      "source": [
        "cordinate[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvusqn2s2BtU"
      },
      "source": [
        "\n",
        "import cv2\n",
        "img = cv2.imread(\"/content/drive/MyDrive/images/train/11_image.jpg\")\n",
        "print(img.shape)\n",
        "for i in cordinate:\n",
        "  count= 0\n",
        "  for val in i:\n",
        "    value = val.strip().split(\" \")\n",
        "    x_min = int(float(value[0])*img.shape[0])\n",
        "    x_max = x_min + int(float(value[2])*img.shape[0])\n",
        "    y_min = int(float(value[1])*img.shape[1])\n",
        "    y_max = y_min + int(float(value[3])*img.shape[1])\n",
        "    crop_img = img[y_min:y_max, x_min:x_max]\n",
        "    cv2.imwrite(f\"Object_{count}.jpg\",crop_img)\n",
        "    count = count + 1\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPBJ1AbJAtvd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6Nj4-gA1uQI"
      },
      "source": [
        "import cv2\n",
        "img = cv2.imread(\"/content/drive/MyDrive/images/train/11_image.jpg\")\n",
        "crop_img = img[y_min:y_max, x_min:x_max]\n",
        "cv2.imwrite(\"Object.jpg\",crop_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}