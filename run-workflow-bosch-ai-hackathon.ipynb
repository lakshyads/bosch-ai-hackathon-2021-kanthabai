{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRAIN_YOLO_V5_FOR_BOSCH_HACKATHON.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "beH-eBRLUKYG"
      },
      "source": [
        "import torch \n",
        "torch.cuda.get_device_name(device=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DBmYXVfJrxp"
      },
      "source": [
        "---\n",
        "---\n",
        "# BOSCH AI HACKATHON 2021\n",
        "---\n",
        "## Team - KanthabAI\n",
        "\n",
        "Members:\n",
        "  - Sanjana\n",
        "  - Lakshya\n",
        "  - Abeesh\n",
        "  - Sachin\n",
        "  - Shubham\n",
        "  \n",
        "~ Code, data and scripts maintained by Lakshya Dev at https://github.com/lakshyads/bosch-ai-hackathon-2021-kanthabai\n",
        "\n",
        "  \n",
        "---\n",
        "**Content:**\n",
        "1. Prep the environment and data\n",
        "2. Training the Yolov5 model\n",
        "3. Running inferences on training data\n",
        "4. Test with test data\n",
        "5. ***Detecting new Images***\n",
        "6. Retraining from last checkpoint\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVZUl7GmuXP9"
      },
      "source": [
        "# 1. PREP THE ENVIRONMENT AND DATA\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj0Liegc7T4z"
      },
      "source": [
        "### Setup git LFS for downloading dataset with repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wGrTCqm5O56"
      },
      "source": [
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLxitPWmw0vF"
      },
      "source": [
        "### Setup git identity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMZkls1qw-E2"
      },
      "source": [
        "!git config --global user.email \"lakshyadev@live.com\"\n",
        "!git config --global user.name \"Lakshya from google colab\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVO58hItFsT4"
      },
      "source": [
        "### Cloning the model and script files from Github repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBAJ4od4UEL3"
      },
      "source": [
        "!git clone https://github.com/lakshyads/bosch-ai-hackathon-2021-kanthabai.git yolov5\n",
        "%cd /content/yolov5/\n",
        "!git checkout trainings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl6BjdGkF2BK"
      },
      "source": [
        "### Ready the dataset included with above repo (extract & split)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu5UjPJTW9GW"
      },
      "source": [
        "%cd /content/yolov5/\n",
        "\n",
        "# Unzip dataset\n",
        "!unzip -q ./data/final-data-full.zip -d /content/yolov5/data/dataset/\n",
        "\n",
        "# =================================================\n",
        "\n",
        "# Set to True to create test set\n",
        "make_test_set = False\n",
        "\n",
        "# =================================================\n",
        "\n",
        "if(make_Test_set is False):\n",
        "  #split dataset without test set\n",
        "  !python /content/yolov5/data-utils/split_train_val_test.py --images /content/yolov5/data/dataset --labels /content/yolov5/data/dataset --out /content/yolov5/data/dataset --move y --test n\n",
        "else:\n",
        "  #split dataset with test set\n",
        "  !python /content/yolov5/data-utils/split_train_val_test.py --images /content/yolov5/data/dataset --labels /content/yolov5/data/dataset --out /content/yolov5/data/dataset --move y --test y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge9PgTIeF6rI"
      },
      "source": [
        "### Installing the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gypm2_zVcm-m"
      },
      "source": [
        "!pip install -r requirements.txt\n",
        "\n",
        "%cd /content/yolov5/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhl6GuxJFml5"
      },
      "source": [
        "### Option to connect and use Google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQjhWx2bIz7R"
      },
      "source": [
        "# =================================================\n",
        "\n",
        "# Set to true to connect to GDrive\n",
        "useGDrive = False\n",
        "\n",
        "# =================================================\n",
        "# =================================================\n",
        "\n",
        "if (useGDrive is True):\n",
        "  %cd ..\n",
        "  !pip install PyDrive\n",
        "\n",
        "  import os\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "\n",
        "  # Connect GDrive\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  # Download zipped data to Colab from Google Drive\n",
        "  download = drive.CreateFile({'id': '1S23A8_uuiE2zp50qJDSp_xcC294kaFW7'})\n",
        "  download.GetContentFile('train-validate-test-split-data.zip')\n",
        "\n",
        "  %cd /content/yolov5\n",
        "else:\n",
        "  print(\"Google Drive will not be used. set useGDrive = True to use G Drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVwCa5WNRWBz"
      },
      "source": [
        "### Give full permissions to everthing inside /content/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhasEsGmWc15"
      },
      "source": [
        "!chmod -R 755 /content/yolov5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QflTgxaqGAkh"
      },
      "source": [
        "### Download all versions of YOLO-V5 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNXcfvaiQ1NV"
      },
      "source": [
        "!/content/yolov5/weights/download_weights.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eonZvqVWHEea"
      },
      "source": [
        "---\n",
        "# 2. TRAINING THE YOLO-V5 MODEL\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ADazUQjgqN0"
      },
      "source": [
        "### Run training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBz4MO3NXVPW"
      },
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 1 --data final-data.yaml --weights yolov5s6.pt --nosave --cache "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSTV7GeyfoM3"
      },
      "source": [
        "### Commit run folder updates to git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F3tZZh55GXe"
      },
      "source": [
        "!git add runs\n",
        "\n",
        "!git status\n",
        "\n",
        "!git commit -m \"Updated runs data after a new execution\"\n",
        "\n",
        "!git push https://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@github.com/lakshyads/bosch-ai-hackathon-2021-kanthabai.git\n",
        "\n",
        "print('Pushed changes in runs/ to git')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r45cXEEV4_Ms"
      },
      "source": [
        "### Zip and upload complete runs folder to GDrive as precaution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC_-Mrh59SU-"
      },
      "source": [
        "# =================================================\n",
        "\n",
        "# Backup run folder to Google drive\n",
        "backup_to_drive = False # setting to True will work only if useGDrive is also True and Gdrive is connected\n",
        "\n",
        "# =================================================\n",
        "# =================================================\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d%m%Y-T-%H%M%S\")\n",
        "model_name = 'yolov5s6'\n",
        "epocs = '150'\n",
        "batch_size = '16'\n",
        "initial_weights = 'pre_Init_Weights'\n",
        "# initial_weights = 'custom_Init_Weights'\n",
        "\n",
        "if(useGDrive is True and backup_to_drive is True):\n",
        "  print('Backing up to google drive')\n",
        "  import shutil\n",
        "  import os\n",
        "\n",
        "  bak_archive_name = f'run-{model_name}-{initial_weights}-epocs_{epocs}-batch_{batch_size}-{dt_string}'\n",
        "  bak_archive_path = r'/content/yolov5/backups-for-gdrive/'\n",
        "  bak_archive = os.path.join(bak_archive_path, bak_archive_name)\n",
        "  dir_to_archive = '/content/yolov5/runs'\n",
        "  try:\n",
        "    print('\\n Trying to upload run folder to gdrive ...')\n",
        "    if not os.path.exists(bak_archive_path):\n",
        "      os.makedirs(bak_archive_path)\n",
        "\n",
        "    shutil.make_archive(base_name=bak_archive, root_dir=dir_to_archive, format= 'zip', base_dir=dir_to_archive)\n",
        "\n",
        "    file = drive.CreateFile({'title': f'{bak_archive_name}.zip', 'parents': [{'id': '1Fo9h4-e-AvGSeYX0Q_086MnP7uquJMyN'}]})\n",
        "    file.SetContentFile(f'{bak_archive}.zip')\n",
        "    file.Upload()  \n",
        "    print(f'\\n Run data uploaded to google drive. Uploaded file name = {bak_archive}')\n",
        "  except Exception as e:\n",
        "    print(f'\\n Failed to upload Run data to GDrive: {bak_archive} to Google Drive. \\nException details: {e}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCwzXHNl5yZj"
      },
      "source": [
        "---\n",
        "# 3. RUNNING INFERENCES ON TRAINING DATA\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJM0X-gQHLig"
      },
      "source": [
        "### Visualizing training metrics using Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1_iKB2AWonF"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCVi44UrwtKx"
      },
      "source": [
        "### Plotting the training results from latest run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyc7jqvsw1u3"
      },
      "source": [
        "from utils.plots import plot_results\n",
        "import os\n",
        "\n",
        "# find the latest run\n",
        "_, dir_names, _ = next(os.walk('runs/train'))\n",
        "dir_names.sort()\n",
        "latest = dir_names[-1] # eg: 'runs/train/exp3'\n",
        "\n",
        "plot_results(save_dir=latest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5STJ2WzXHVPx"
      },
      "source": [
        "---\n",
        "# 4. TESTING\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_PJu4QB7x93"
      },
      "source": [
        "### Update --weights with required weights path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkcJGHFmcPf3"
      },
      "source": [
        "# Update --weights path as required\n",
        "!python test.py --weights /content/yolov5/runs/train/exp3/weights/best.pt --data final-data.yaml --img 640"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6idZoQ1761B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmHmIw9L7swd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9AV1cUQHSLg"
      },
      "source": [
        "---\n",
        "# 5. DETECTING ON NEW IMAGES\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4DIYurLi6w"
      },
      "source": [
        "### Extract new images from zipped upload\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGBpkN0GLnVX"
      },
      "source": [
        "%cd ..\n",
        "# !unzip -q /content/extracted_images.zip \n",
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okqavNfL7-7s"
      },
      "source": [
        "### Runs the detect script.\n",
        "### Update --weights with required weights path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R3aBtYFr_5d"
      },
      "source": [
        "!python detect.py --source /content/extracted_images --weights /content/last.pt --img 640 --save-txt --save-conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yh2zd2AHkUg"
      },
      "source": [
        "---\n",
        "# 6. RETRAINING FROM THE LAST CHECKPOINT\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r732j58annF4"
      },
      "source": [
        "!python train.py --weights /content/yolov5/runs/train/exp2/weights/last.pt --epochs 100 --img 416"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1KbWCaf8EVu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}